# Open WebUI Rating System ‚Üí The Steward Feedback Loop\n\n## Overview\n\nThe Steward now captures and learns from Open WebUI's chat rating system! When you thumbs up/down or rate responses in Open WebUI, that feedback flows back to The Steward's routing engine to improve future decisions.\n\n## How It Works\n\n### **1. You Rate a Response in Open WebUI**\n- Thumbs up/down a message\n- Give a 1-5 star rating\n- Add detailed feedback comments\n\n### **2. Open WebUI Sends Feedback to The Steward**\n- Rating data posted to `/v1/feedback` endpoint\n- Includes The Steward's original routing metadata\n- Links rating to specific routing decision\n\n### **3. The Steward Learns and Adapts**\n- Analyzes which routing decisions got positive/negative feedback\n- Tracks successful task-type ‚Üí model pairings\n- Identifies failed routing patterns for improvement\n- Updates routing confidence and preferences\n\n## Feedback Data Flow\n\n```\nOpen WebUI Rating ‚Üí The Steward Analysis ‚Üí Routing Improvement\n     ‚Üì                      ‚Üì                      ‚Üì\n\"üëç Great code help\"    \"Creative task +      \"Future creative tasks\n                        GPT-4 = Success\"      ‚Üí prefer GPT-4\"\n```\n\n## What Gets Tracked\n\n### **Positive Feedback (üëç / 4-5 stars)**\n- **Successful Pairings:** Task type + model combinations that work well\n- **Confidence Boost:** Increase confidence in similar routing decisions\n- **Preference Learning:** Strengthen character sheet preferences\n- **Pattern Recognition:** Identify consistently successful routes\n\n### **Negative Feedback (üëé / 1-2 stars)**\n- **Failed Pairings:** Task type + model combinations to avoid\n- **Alternative Suggestions:** Flag need for different model selection\n- **Route Adjustment:** Modify routing logic for similar future tasks\n- **Confidence Reduction:** Lower confidence in similar patterns\n\n### **Neutral Feedback (3 stars)**\n- **Acceptable Performance:** Routing worked but could be better\n- **Baseline Data:** Helps establish performance benchmarks\n- **Gradual Learning:** Subtle adjustments to routing weights\n\n## Feedback Analytics\n\n### **Real-Time Learning**\nEvery rating immediately influences:\n- Character sheet preference weights\n- Task classification confidence thresholds\n- Model selection probability scores\n- Routing decision trees\n\n### **Historical Analysis**\nFeedback data builds:\n- Performance trends over time\n- User preference evolution\n- Model effectiveness by task type\n- Cognitive load optimization patterns\n\n### **Feedback Logs**\nAll feedback stored in:\n- **File:** `/logs/feedback.jsonl`\n- **Format:** One JSON object per line\n- **Content:** Rating + routing decision + analysis\n\n## Example Feedback Scenarios\n\n### **Code Debugging Success**\n```json\n{\n  \"rating\": 5,\n  \"task_classification\": \"debug\",\n  \"selected_model\": \"gpt-4\",\n  \"routing_successful\": true,\n  \"successful_pairing\": {\n    \"task_type\": \"debug\",\n    \"model\": \"gpt-4\",\n    \"confidence_threshold\": 0.85\n  }\n}\n```\n**Result:** Future debug tasks more likely to route to GPT-4\n\n### **Creative Writing Disappointment**\n```json\n{\n  \"rating\": 2,\n  \"task_classification\": \"creative\",\n  \"selected_model\": \"ai/smollm3:latest\",\n  \"routing_successful\": false,\n  \"failed_pairing\": {\n    \"task_type\": \"creative\",\n    \"model\": \"ai/smollm3:latest\",\n    \"suggest_alternative\": true\n  }\n}\n```\n**Result:** Creative tasks less likely to use SmolLM3, prefer GPT-4 or Claude\n\n### **Speed vs Quality Tradeoff**\n```json\n{\n  \"rating\": 3,\n  \"task_classification\": \"general\",\n  \"selected_model\": \"ai/smollm3:latest\", \n  \"user_feedback\": \"Fast but could be more detailed\",\n  \"routing_successful\": \"neutral\"\n}\n```\n**Result:** Adjust speed vs quality balance for general tasks\n\n## Viewing Feedback Analytics\n\n### **Real-Time Feedback**\nWatch feedback processing in logs:\n```bash\ntail -f logs/steward.log | grep \"üìä Feedback\"\n```\n\n### **Feedback History**\nView all feedback data:\n```bash\ncat logs/feedback.jsonl | jq .\n```\n\n### **Feedback Summary**\nGet feedback analytics:\n```bash\ncat logs/feedback.jsonl | jq -s 'map(select(.rating)) | group_by(.rating) | map({rating: .[0].rating, count: length})'\n```\n\n### **Model Performance by Rating**\n```bash\ncat logs/feedback.jsonl | jq -s 'map(select(.selected_model)) | group_by(.selected_model) | map({model: .[0].selected_model, avg_rating: (map(.rating) | add / length)})'\n```\n\n## Optimizing Your Experience\n\n### **Rate Strategically**\n- **Be specific:** Rate based on how well the response solved your need\n- **Consider context:** Factor in speed vs quality expectations\n- **Think routing:** Consider if a different model might have been better\n\n### **Use Feedback Comments**\nDetailed feedback helps The Steward learn:\n- \"Too slow for a simple question\"\n- \"Perfect creative response!\"\n- \"Good analysis but could be more detailed\"\n- \"Wrong model choice for debugging\"\n\n### **Rate Consistently**\nYour rating patterns help establish:\n- Personal preference baselines\n- Task-specific quality expectations\n- Speed vs accuracy tradeoffs\n- ADHD accommodation effectiveness\n\n## Advanced Features\n\n### **Adaptive Character Sheet**\nFeedback automatically adjusts:\n- Task type preferences based on ratings\n- Model selection weights by performance\n- Response style preferences from comments\n- Cognitive load accommodations by satisfaction\n\n### **Learning Acceleration**\n- **High confidence ratings** (5 stars) strongly reinforce routing\n- **Low confidence ratings** (1-2 stars) trigger immediate pattern updates\n- **Frequent patterns** get higher learning weights\n- **Recent feedback** influences decisions more than old data\n\n### **Multi-User Learning**\nIf multiple users rate through Open WebUI:\n- Individual user patterns tracked separately\n- Common successful patterns shared across users\n- Personal preferences maintained individually\n- Collective intelligence improves base routing\n\n## Troubleshooting\n\n### **Feedback Not Registering**\n1. Check Open WebUI is sending to correct endpoint\n2. Verify The Steward logs show \"üìä Feedback received\"\n3. Ensure steward_metadata is included in responses\n\n### **No Learning Improvements**\n1. Check feedback.jsonl file exists and has data\n2. Verify ratings cover range of scenarios\n3. Allow time for pattern recognition (10+ ratings)\n4. Check character sheet updates reflect feedback\n\n### **Unexpected Routing Changes**\n1. Review recent feedback patterns in logs\n2. Check if negative feedback triggered route adjustments\n3. Verify feedback ratings align with expectations\n4. Reset learning data if needed (backup first)\n\n## Impact on The Steward Evolution\n\nThis feedback loop transforms The Steward from a **smart router** into a **learning AI coordinator**:\n\n- ‚úÖ **Personalized:** Adapts to your specific preferences and workflow\n- ‚úÖ **Self-Improving:** Gets better with every interaction and rating\n- ‚úÖ **Context-Aware:** Learns situational preferences (speed vs quality)\n- ‚úÖ **ADHD-Optimized:** Refines accommodations based on satisfaction\n- ‚úÖ **Transparent:** Full visibility into learning and decision process\n\n**Your ratings in Open WebUI directly shape how The Steward routes future tasks - making it truly collaborative AI!** üöÄ\n